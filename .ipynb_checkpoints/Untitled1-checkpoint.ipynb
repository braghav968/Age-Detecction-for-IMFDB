{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from os import environ\n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "# user defined function to change keras backend\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "       environ['KERAS_BACKEND'] = backend\n",
    "       reload(K)\n",
    "       assert K.backend() == backend\n",
    "\n",
    "# call the function with \"theano\"\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "import matplotlib.pylab as pylab\n",
    "import cv2\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17814.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21283.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16496.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4487.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   Class\n",
       "0    377.jpg  MIDDLE\n",
       "1  17814.jpg   YOUNG\n",
       "2  21283.jpg  MIDDLE\n",
       "3  16496.jpg   YOUNG\n",
       "4   4487.jpg  MIDDLE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv('train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\Train1\\23790.jpg\n",
      "23790.jpg\n"
     ]
    }
   ],
   "source": [
    "img_name = rng.choice(train_csv.ID)\n",
    "filepath = os.path.join('data','Train1', img_name)\n",
    "print(filepath)\n",
    "print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "for img_name in train_csv.ID:\n",
    "    image_path = os.path.join('Train1',img_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    img = np.array(img, dtype = 'float32')\n",
    "    img_array.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "train_x = np.stack(img_array)\n",
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_csv.Class)\n",
    "encoded_labels = encoder.transform(train_csv.Class)\n",
    "train_y = np_utils.to_categorical(encoded_labels)\n",
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(64,3,3,input_shape = (32,32,3), activation = 'relu')) #Adding the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(15, 15, 3..., activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(64,3,3,input_shape = (15,15,3), activation = 'relu')) #Adding the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2))) #Applying Max Pooling to the convlved matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten()) #Flattening the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  after removing the cwd from sys.path.\n",
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=3)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Full Connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 367,171\n",
      "Trainable params: 367,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile( optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 20 #As the size of images is small so we can afford small batch size for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\MiniConda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19906/19906 [==============================] - 9s 471us/step - loss: 0.0471 - acc: 0.9833\n",
      "Epoch 2/30\n",
      "19906/19906 [==============================] - 8s 395us/step - loss: 0.0531 - acc: 0.9808\n",
      "Epoch 3/30\n",
      "19906/19906 [==============================] - 9s 451us/step - loss: 0.0500 - acc: 0.9820\n",
      "Epoch 4/30\n",
      "19906/19906 [==============================] - 9s 462us/step - loss: 0.0462 - acc: 0.9836\n",
      "Epoch 5/30\n",
      "19906/19906 [==============================] - 9s 445us/step - loss: 0.0454 - acc: 0.9843\n",
      "Epoch 6/30\n",
      "19906/19906 [==============================] - 9s 433us/step - loss: 0.0410 - acc: 0.9857\n",
      "Epoch 7/30\n",
      "19906/19906 [==============================] - 8s 424us/step - loss: 0.0456 - acc: 0.9842\n",
      "Epoch 8/30\n",
      "19906/19906 [==============================] - 9s 427us/step - loss: 0.0396 - acc: 0.9864\n",
      "Epoch 9/30\n",
      "19906/19906 [==============================] - 8s 426us/step - loss: 0.0428 - acc: 0.9856\n",
      "Epoch 10/30\n",
      "19906/19906 [==============================] - 8s 427us/step - loss: 0.0411 - acc: 0.9854\n",
      "Epoch 11/30\n",
      "19906/19906 [==============================] - 8s 390us/step - loss: 0.0388 - acc: 0.9858\n",
      "Epoch 12/30\n",
      "19906/19906 [==============================] - 8s 388us/step - loss: 0.0333 - acc: 0.9888\n",
      "Epoch 13/30\n",
      "19906/19906 [==============================] - 8s 389us/step - loss: 0.0426 - acc: 0.9851\n",
      "Epoch 14/30\n",
      "19906/19906 [==============================] - 9s 437us/step - loss: 0.0323 - acc: 0.9888\n",
      "Epoch 15/30\n",
      "19906/19906 [==============================] - 8s 404us/step - loss: 0.0387 - acc: 0.9867\n",
      "Epoch 16/30\n",
      "19906/19906 [==============================] - 7s 374us/step - loss: 0.0300 - acc: 0.9905\n",
      "Epoch 17/30\n",
      "19906/19906 [==============================] - 7s 358us/step - loss: 0.0321 - acc: 0.9890\n",
      "Epoch 18/30\n",
      "19906/19906 [==============================] - 7s 336us/step - loss: 0.0334 - acc: 0.9886\n",
      "Epoch 19/30\n",
      "19906/19906 [==============================] - 7s 366us/step - loss: 0.0339 - acc: 0.9893\n",
      "Epoch 20/30\n",
      "19906/19906 [==============================] - 7s 344us/step - loss: 0.0358 - acc: 0.9890\n",
      "Epoch 21/30\n",
      "19906/19906 [==============================] - 9s 439us/step - loss: 0.0292 - acc: 0.9905\n",
      "Epoch 22/30\n",
      "19906/19906 [==============================] - 8s 402us/step - loss: 0.0292 - acc: 0.9913\n",
      "Epoch 23/30\n",
      "19906/19906 [==============================] - 8s 384us/step - loss: 0.0301 - acc: 0.9905\n",
      "Epoch 24/30\n",
      "19906/19906 [==============================] - 7s 369us/step - loss: 0.0346 - acc: 0.9890\n",
      "Epoch 25/30\n",
      "19906/19906 [==============================] - 7s 357us/step - loss: 0.0263 - acc: 0.9914\n",
      "Epoch 26/30\n",
      "19906/19906 [==============================] - 7s 367us/step - loss: 0.0233 - acc: 0.9926\n",
      "Epoch 27/30\n",
      "19906/19906 [==============================] - 8s 394us/step - loss: 0.0283 - acc: 0.9912\n",
      "Epoch 28/30\n",
      "19906/19906 [==============================] - 7s 367us/step - loss: 0.0280 - acc: 0.9900\n",
      "Epoch 29/30\n",
      "19906/19906 [==============================] - 7s 362us/step - loss: 0.0276 - acc: 0.9908\n",
      "Epoch 30/30\n",
      "19906/19906 [==============================] - 7s 364us/step - loss: 0.0221 - acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212d9ccaeb8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_arr = []\n",
    "for im in glob.glob('data/Test/*.jpg'):\n",
    "    img_1 = cv2.imread(im)\n",
    "    img_1 = cv2.resize(img, (32,32))\n",
    "    test_img_arr.append(np.array(img_1,dtype = 'float32'))\n",
    "test_x = np.stack(test_img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_y = LabelEncoder().fit_transform(train_csv.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-8561200df111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\MiniConda\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'classes_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;31m# inverse transform of empty array is empty array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\MiniConda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(test_x)\n",
    "pred = LabelEncoder().inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9998903e-01 4.9096802e-06 6.0984125e-06]\n",
      " [9.9998903e-01 4.9096802e-06 6.0984125e-06]\n",
      " [9.9998903e-01 4.9096802e-06 6.0984125e-06]\n",
      " ...\n",
      " [9.9998903e-01 4.9096802e-06 6.0984125e-06]\n",
      " [9.9998903e-01 4.9096802e-06 6.0984125e-06]\n",
      " [9.9998903e-01 4.9096802e-06 6.0984125e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
